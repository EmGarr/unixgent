//! LLM-based security judge for command evaluation.
//!
//! Provides defense-in-depth by running an independent LLM call to evaluate
//! proposed commands before showing them to the user. The judge only receives
//! the commands, the user's instruction, and the working directory â€” never
//! terminal output, conversation history, or environment variables.

use serde::Deserialize;
use ua_backend::AnthropicClient;

/// Verdict from the security judge.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum JudgeVerdict {
    /// Commands appear safe to execute.
    Safe,
    /// Commands may be unsafe. Includes reasoning for the warning.
    Unsafe { reasoning: String },
    /// Judge encountered an error (non-blocking).
    Error(String),
}

#[derive(Debug, Deserialize)]
struct JudgeResponse {
    safe: bool,
    reasoning: String,
}

/// Evaluate proposed commands using an independent LLM call.
///
/// The judge receives only the commands, the user's instruction, and the
/// working directory. It never sees terminal output, conversation history,
/// or environment variables.
pub async fn evaluate_commands(
    client: &AnthropicClient,
    commands: &[String],
    instruction: &str,
    cwd: &str,
) -> JudgeVerdict {
    let system = judge_system_prompt();
    let user_msg = judge_user_message(commands, instruction, cwd);

    match client.send_non_streaming(system, &user_msg).await {
        Ok(text) => parse_judge_response(&text),
        Err(e) => JudgeVerdict::Error(format!("judge API call failed: {e}")),
    }
}

fn judge_system_prompt() -> &'static str {
    r#"You are an independent security judge for a Unix shell agent. Your job is to evaluate proposed shell commands for safety risks.

You will receive:
1. One or more shell commands the agent wants to execute
2. The user's original instruction
3. The current working directory

Evaluate the commands for these risk categories:
1. DATA EXFILTRATION: Commands that send data to external servers (curl POST, wget upload, nc, ssh with piped data, etc.)
2. CONFIG MODIFICATION: Changes to dotfiles, shell configs, SSH configs, crontabs, or system configs that could persist after the session
3. BACKDOORS: Commands that install persistent access (SSH keys, cron jobs, startup scripts, reverse shells)
4. OBFUSCATION: Base64-encoded commands, hex-encoded payloads, eval of constructed strings, or other techniques to hide intent
5. REMOTE CODE EXECUTION: Downloading and executing scripts from the internet (curl | bash, wget + chmod + exec)
6. PRIVILEGE ESCALATION: Use of sudo, su, setuid, capability changes, or exploiting writable system paths
7. SCOPE CREEP: Commands that go significantly beyond what the user asked for (e.g., user asks to list files but agent deletes them)
8. SENSITIVE FILE ACCESS: Reading or modifying SSH keys, GPG keys, password files, token stores, or credential files

Respond with a JSON object:
{"safe": true, "reasoning": "Brief explanation of why the commands are safe"}
or
{"safe": false, "reasoning": "Brief explanation of the specific risk identified"}

Respond ONLY with the JSON object. No other text."#
}

fn judge_user_message(commands: &[String], instruction: &str, cwd: &str) -> String {
    let commands_formatted: Vec<String> = commands
        .iter()
        .enumerate()
        .map(|(i, cmd)| format!("{}. {}", i + 1, cmd))
        .collect();

    format!(
        "Commands:\n{}\n\nUser instruction: {}\n\nWorking directory: {}",
        commands_formatted.join("\n"),
        instruction,
        cwd
    )
}

fn parse_judge_response(text: &str) -> JudgeVerdict {
    // Try to extract JSON from the response, handling markdown fences
    let json_str = extract_json(text);

    match serde_json::from_str::<JudgeResponse>(json_str) {
        Ok(resp) => {
            if resp.safe {
                JudgeVerdict::Safe
            } else {
                JudgeVerdict::Unsafe {
                    reasoning: resp.reasoning,
                }
            }
        }
        Err(e) => JudgeVerdict::Error(format!("failed to parse judge response: {e}")),
    }
}

/// Extract JSON from text that may contain markdown fences or surrounding text.
fn extract_json(text: &str) -> &str {
    let trimmed = text.trim();

    // Try markdown fence extraction: ```json ... ``` or ``` ... ```
    if let Some(start) = trimmed.find("```") {
        let after_fence = &trimmed[start + 3..];
        // Skip optional language tag (e.g., "json")
        let content_start = after_fence.find('\n').map(|i| i + 1).unwrap_or(0);
        let content = &after_fence[content_start..];
        if let Some(end) = content.find("```") {
            return content[..end].trim();
        }
    }

    // Try to find a JSON object directly
    if let Some(start) = trimmed.find('{') {
        if let Some(end) = trimmed.rfind('}') {
            return &trimmed[start..=end];
        }
    }

    trimmed
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn judge_system_prompt_contains_risk_categories() {
        let prompt = judge_system_prompt();
        assert!(prompt.contains("DATA EXFILTRATION"));
        assert!(prompt.contains("CONFIG MODIFICATION"));
        assert!(prompt.contains("BACKDOORS"));
        assert!(prompt.contains("OBFUSCATION"));
        assert!(prompt.contains("REMOTE CODE EXECUTION"));
        assert!(prompt.contains("PRIVILEGE ESCALATION"));
        assert!(prompt.contains("SCOPE CREEP"));
        assert!(prompt.contains("SENSITIVE FILE ACCESS"));
    }

    #[test]
    fn judge_system_prompt_has_no_secrets() {
        let prompt = judge_system_prompt();
        assert!(!prompt.contains("sk-ant-"));
        assert!(!prompt.contains("ANTHROPIC_API_KEY"));
        assert!(!prompt.contains("api_key"));
    }

    #[test]
    fn judge_user_message_formatting() {
        let msg = judge_user_message(
            &["ls /tmp".to_string(), "cat file.txt".to_string()],
            "list temporary files",
            "/home/user",
        );
        assert!(msg.contains("1. ls /tmp"));
        assert!(msg.contains("2. cat file.txt"));
        assert!(msg.contains("User instruction: list temporary files"));
        assert!(msg.contains("Working directory: /home/user"));
    }

    #[test]
    fn parse_clean_json_safe() {
        let text = r#"{"safe": true, "reasoning": "These are read-only commands."}"#;
        let verdict = parse_judge_response(text);
        assert_eq!(verdict, JudgeVerdict::Safe);
    }

    #[test]
    fn parse_clean_json_unsafe() {
        let text =
            r#"{"safe": false, "reasoning": "This downloads and executes a remote script."}"#;
        let verdict = parse_judge_response(text);
        assert_eq!(
            verdict,
            JudgeVerdict::Unsafe {
                reasoning: "This downloads and executes a remote script.".to_string()
            }
        );
    }

    #[test]
    fn parse_markdown_wrapped_json() {
        let text = "```json\n{\"safe\": true, \"reasoning\": \"Safe commands.\"}\n```";
        let verdict = parse_judge_response(text);
        assert_eq!(verdict, JudgeVerdict::Safe);
    }

    #[test]
    fn parse_markdown_no_language_tag() {
        let text = "```\n{\"safe\": false, \"reasoning\": \"Risky.\"}\n```";
        let verdict = parse_judge_response(text);
        assert_eq!(
            verdict,
            JudgeVerdict::Unsafe {
                reasoning: "Risky.".to_string()
            }
        );
    }

    #[test]
    fn parse_json_with_surrounding_text() {
        let text = "Here is my evaluation:\n{\"safe\": true, \"reasoning\": \"All good.\"}\nEnd.";
        let verdict = parse_judge_response(text);
        assert_eq!(verdict, JudgeVerdict::Safe);
    }

    #[test]
    fn parse_missing_fields() {
        let text = r#"{"safe": true}"#;
        let verdict = parse_judge_response(text);
        assert!(matches!(verdict, JudgeVerdict::Error(_)));
    }

    #[test]
    fn parse_empty_response() {
        let verdict = parse_judge_response("");
        assert!(matches!(verdict, JudgeVerdict::Error(_)));
    }

    #[test]
    fn parse_invalid_json() {
        let verdict = parse_judge_response("not json at all");
        assert!(matches!(verdict, JudgeVerdict::Error(_)));
    }

    #[test]
    fn judge_user_message_single_command() {
        let msg = judge_user_message(
            &["rm -rf /tmp/build".to_string()],
            "clean build",
            "/project",
        );
        assert!(msg.contains("1. rm -rf /tmp/build"));
        assert!(!msg.contains("2."));
    }
}
